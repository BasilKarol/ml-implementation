{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Scalers implementation:\n",
    " - MinMaxStandardizer\n",
    " - NormalStandardizer\n",
    " - RobustStandardizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn import preprocessing as prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract Standardizer Class for further inheritation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsStandardizer(ABC):\n",
    "    '''\n",
    "     - data_to_stadnardize: dict[str : np.array]\n",
    "        Dictionary with keys as data names (headers) and values as numpy matrix, \n",
    "    representing data. \n",
    "     - data: dict[str : np.array]:\n",
    "        Standardized data is stored here.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **data_to_stadnardize):\n",
    "        self.data_to_stadnardize = data_to_stadnardize\n",
    "        self.data = {}\n",
    "        self.init_normalization()    \n",
    "    \n",
    "    def __getitem__(self, key: str) -> np.array:\n",
    "        return self.data[key]\n",
    "    \n",
    "    @abstractmethod\n",
    "    def init_normalization(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def normalize(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def denormalize(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Standardizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxStandardizer(AbsStandardizer):\n",
    "\n",
    "    def init_normalization(self):\n",
    "        self._params = {}\n",
    "        for key, value in self.data_to_stadnardize.items():\n",
    "            data_min, data_max = value.min(axis=0), value.max(axis=0)\n",
    "            # Storing the Standarsizer main parameters into dictionary:\n",
    "            self._params.update(\n",
    "               {\n",
    "                   key : {\n",
    "                        \"min\" : data_min,\n",
    "                        \"max\" : data_max\n",
    "                        }\n",
    "                }\n",
    "            )\n",
    "            self.data[key] = (value - data_min) / (data_max - data_min)\n",
    "    \n",
    "    def normalize(self, data: np.array, key: str) -> np.array:\n",
    "        return (data - self._params[key][\"min\"]) \\\n",
    "                / (self._params[key][\"max\"] - self._params[key][\"min\"])\n",
    "    \n",
    "    def denormalize(self, data: np.array, key: str) -> np.array:\n",
    "        return data * (self._params[key][\"max\"] - self._params[key][\"min\"]) \\\n",
    "            + self._params[key][\"min\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Standardizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalStandardizer(AbsStandardizer):\n",
    "\n",
    "    def init_normalization(self):\n",
    "        self._params = {}\n",
    "        for key, value in self.data_to_stadnardize.items():\n",
    "            data_mean, data_std = value.mean(axis=0), value.std(axis=0)\n",
    "            # Storing the Standarsizer main parameters into dictionary:\n",
    "            self._params.update(\n",
    "               {\n",
    "                   key : {\n",
    "                        \"mean\" : data_mean,\n",
    "                        \"std\" : data_std\n",
    "                        }\n",
    "                }\n",
    "            )\n",
    "            self.data[key] = (value - data_mean) / data_std\n",
    "        \n",
    "    def normalize(self, data: np.array, key: str) -> np.array:\n",
    "        return (data - self._params[key][\"mean\"]) / self._params[key][\"std\"]\n",
    "    \n",
    "    def denormalize(self, data: np.array, key: str) -> np.array:\n",
    "        return data * self._params[key][\"std\"] + self._params[key][\"std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Standardizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustStandardizer(AbsStandardizer):\n",
    "\n",
    "    def init_normalization(self):\n",
    "        self._params = {}\n",
    "        for key, value in self.data_to_stadnardize.items():\n",
    "            data_q1, data_q3 = np.quantile(value, 0.25, axis=0), np.quantile(value, 0.75, axis=0)\n",
    "            data_median = np.median(value, axis=0)\n",
    "            # Storing the Standarsizer main parameters into dictionary:\n",
    "            self._params.update(\n",
    "                {\n",
    "                    key : {\n",
    "                        \"q1\" : data_q1,\n",
    "                        \"median\" : data_median,\n",
    "                        \"q3\" : data_q3\n",
    "                        }\n",
    "                }\n",
    "            )\n",
    "            self.data[key] = (value - data_median) / (data_q3 - data_q1)\n",
    "        \n",
    "    def normalize(self, data: np.array, key: str) -> np.array:\n",
    "        return (data - self._params[key][\"median\"]) / ( self._params[key][\"q3\"] - self._params[key][\"q1\"] )\n",
    "    \n",
    "    def denormalize(self, data: np.array, key: str) -> np.array:\n",
    "        return data * (self._params[key][\"q3\"] - self._params[key][\"q1\"]) \\\n",
    "            + self._params[key][\"median\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing by comparing to SK-learn implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data_x = np.array([ [-41, 151, 55], [34, 10, -20], [44, -45, 51] ])\n",
    "dummy_data_y = np.array([-41, 151, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MinMax*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My params: [-41 -45 -20], [ 44 151  55];\n",
      "SK params: [-41. -45. -20.], [ 44. 151.  55.].\n"
     ]
    }
   ],
   "source": [
    "minmax_scaler = MinMaxStandardizer(dummy_x=dummy_data_x, dummy_y=dummy_data_y)\n",
    "sk_minmax = prep.MinMaxScaler().fit(dummy_data_x)\n",
    "\n",
    "print(f\"My params: {minmax_scaler._params['dummy_x']['min']}, {minmax_scaler._params['dummy_x']['max']};\")\n",
    "print(f\"SK params: {sk_minmax.data_min_}, {sk_minmax.data_max_}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Standard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My params: [12.33333333 38.66666667 28.66666667], [37.93268892 82.54426422 34.45125381];\n",
      "SK params: [12.33333333 38.66666667 28.66666667], [37.93268892 82.54426422 34.45125381].\n"
     ]
    }
   ],
   "source": [
    "normal_scaler = NormalStandardizer(dummy_x=dummy_data_x, dummy_y=dummy_data_y)\n",
    "sk_normal = prep.StandardScaler().fit(dummy_data_x)\n",
    "\n",
    "print(f\"My params: {normal_scaler._params['dummy_x']['mean']}, {normal_scaler._params['dummy_x']['std']};\")\n",
    "print(f\"SK params: {sk_normal.mean_}, {sk_normal.scale_}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Robust*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My params: [34. 10. 51.], [42.5 98.  37.5]\n",
      "SK params: [34. 10. 51.], [42.5 98.  37.5].\n"
     ]
    }
   ],
   "source": [
    "robust_scaler = RobustStandardizer(dummy_x=dummy_data_x, dummy_y=dummy_data_y)\n",
    "sk_robust = prep.RobustScaler().fit(dummy_data_x)\n",
    "\n",
    "IQR = robust_scaler._params['dummy_x']['q3'] - robust_scaler._params['dummy_x']['q1']\n",
    "print(f\"My params: {robust_scaler._params['dummy_x']['median']}, {IQR}\")\n",
    "print(f\"SK params: {sk_robust.center_}, {sk_robust.scale_}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-impl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
